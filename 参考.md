using Microsoft.Agents.AI;
using Microsoft.Extensions.AI;
using Microsoft.Extensions.Logging;
using Subtitles.Translate.Agent.Core.Models;
using Subtitles.Translate.Agent.Core.Utils;
using System.Text;
using System.Text.Json.Serialization;

namespace Subtitles.Translate.Agent.Core.Agents
{
    /// <summary>
    /// Step 1: Director Agent
    /// Responsible for analyzing video content, establishing translation guidelines and style guides
    /// </summary>
    public class Step1_DirectorAgent : AgentBase
    {
        public const string AgentName = nameof(Step1_DirectorAgent);
        private readonly AIAgent _agent;

        public Step1_DirectorAgent(WorkflowContext context)
            : base(context, AgentName)
        {
            // Create ChatClient and initialize Agent
            var client = CreateChatClient();
            _agent = client.CreateAIAgent().AsBuilder().Build();
        }
    
        public override async Task ExecuteAsync()
        {
            _logger?.LogInformation("===== {AgentName} started execution =====", AgentName);
            if (_context.Subtitle == null)
            {
                throw new Exception("No subtitle content was recognized");
            }
            // Format subtitle
            _context.FormattedSubtitle = SubtitleFormatUtility.ToCustomFormat(_context.Subtitle);
            _logger?.LogDebug("Subtitle formatting completed, total {Count} subtitles, target language: {TargetLanguage}",
                _context.Subtitle.Paragraphs.Count,
                _context.Request.TargetLanguage);
    
            var prompt = GetPrompt();
            _logger?.LogDebug("Prompt length: {Length} chars", prompt.Length);
    
            _logger?.LogInformation("Calling LLM (Model: {ModelId})...", _agentConfig.ModelId);
            var response = await _agent.RunAsync(prompt);
            _logger?.LogInformation("LLM response completed");
    
            // Record Token usage to context
            RecordTokenUsage(AgentName, response.Usage);
            _logger?.LogDebug("Token Usage - Input: {Input}, Output: {Output}, Total: {Total}",
                response.Usage?.InputTokenCount ?? 0,
                response.Usage?.OutputTokenCount ?? 0,
                response.Usage?.TotalTokenCount ?? 0);
    
            // Save raw response
            _context.Step1_DirectorRaw = response.Text;
            _logger?.LogDebug("Raw response length: {Length} chars", response.Text?.Length ?? 0);
    
            // Use base class method to extract and parse JSON
            _context.Step1_DirectorResult = ParseJsonResponse<Step1_DirectorResult>(response.Text ?? string.Empty);
    
            // Output parsing result summary
            if (_context.Step1_DirectorResult != null)
            {
                var result = _context.Step1_DirectorResult;
                _logger?.LogDebug("Parsing successful:");
                _logger?.LogDebug(_context.Step1_DirectorResult.ToMarkdown());
            }
            else
            {
                throw new Exception("Step 1: Result Is null");
            }
    
            _logger?.LogInformation("===== {AgentName} execution completed =====", AgentName);
        }
    
        public string GetPrompt()
        {
            var prompt = $$"""
# Role
You are a senior Multimedia Localization Specialist. Your core capability is to quickly analyze various types of video texts (movies, news, tech tutorials, Vlogs, documentaries, etc.) to provide a precise **Context Framework** and **Style Guide** for the translation team.

# Task
Read the provided video subtitle text and generate a structured **JSON Translation Guidance Document**. This document will serve as the "Global Context" input for the subsequent AI translation process.

# Goal
Your goal is not to "translate", but to establish "translation guidelines". You need to address the following core issues based on the content type:
1.  **Register**: Is it solemn (news/academic), relaxed and humorous (short video), or intimate/flirtatious (adult)?
2.  **Audience**: Who is the content for? This determines the choice of pronouns (e.g., "you" informal vs formal) and the level of professional terminology.
3.  **Core Intent**: Is the purpose to educate, entertain, persuade, or document?

# Analysis Requirements (JSON Fields)

Please generate a JSON object containing the following fields:

* `category`: Specific category of the video (e.g., Python Tutorial, Cyberpunk Movie, Political News, Daily Vlog, Adult/Drama, Movie, TV Series).
* `overall_tone`: 3-5 adjectives summarizing the overall tone (e.g., objective, passionate, slang-heavy, seductive).
* `style_instruction`: Specific instructions for translation. Clearly state the writing style to be adopted (e.g., "Use rigorous written language, avoid colloquialisms" or "Use a lot of current internet slang, keep it grounded").
* `pronoun_rules`: Clarify relationships between characters/speakers and address strategies (e.g., "Speaker is a teacher, use friendly 'everyone' or equal 'you' for audience", "Couples use intimate addresses").
* `summary`: Concisely summarize the main content. If it's a drama, summarize the plot direction; if it's teaching/news, summarize the core theme and conclusion.
* `background_setting`: Supplement necessary background information (e.g., time and place, specific software versions involved, specific social events).

# Constraints
1.  **JSON Only**: Output must be pure JSON format, strictly forbidding any explanatory text other than Markdown tags (` ```json `).
2.  **English Keys**: JSON Keys must be in English.
3.  **Target Language Values**: Please use {{_context.Request.TargetLanguage}} for JSON Value content, so that subsequent translation steps can understand directly.

# Subtitle Content
{{_context.FormattedSubtitle}}

# Output Example
{
    "category": "Tech Review",
    "overall_tone": ["Fast-paced", "Sharp", "Humorous"],
    "style_instruction": "Maintain a YouTuber-like colloquial style. Professional terms (like high refresh rate, ray tracing) must be accurate, but conjunctions can be casual to reflect the blogger's personal opinion.",
    "pronoun_rules": "Blogger refers to self as 'I', calls audience 'bros' or 'everyone', maintaining a sense of community.",
    "summary": "Blogger is comparing camera functions of iPhone 16 and Samsung S25. First half complains about iPhone ghosting, second half praises Samsung telephoto, finally suggests photography enthusiasts choose Samsung.",
    "background_setting": "After the 2025 autumn new product launch, there is huge controversy in the market regarding the two flagships."
}
""";

            return prompt;
        }
    }
    
    #region Step1 Result Models
    
    /// <summary>
    /// Step 1 Director Analysis Result
    /// </summary>
    public class Step1_DirectorResult
    {
        /// <summary>
        /// Specific category of the video
        /// </summary>
        [JsonPropertyName("category")]
        public string Category { get; set; } = string.Empty;
    
        /// <summary>
        /// 3-5 adjectives summarizing overall tone
        /// </summary>
        [JsonPropertyName("overall_tone")]
        public List<string> OverallTone { get; set; } = new();
    
        /// <summary>
        /// Specific instructions for translation, clarifying writing style
        /// </summary>
        [JsonPropertyName("style_instruction")]
        public string StyleInstruction { get; set; } = string.Empty;
    
        /// <summary>
        /// Clarify relationships and address strategies between characters/speakers
        /// </summary>
        [JsonPropertyName("pronoun_rules")]
        public string PronounRules { get; set; } = string.Empty;


        /// <summary>
        /// Concisely summarize content main idea
        /// </summary>
        [JsonPropertyName("summary")]
        public string Summary { get; set; } = string.Empty;
    
        /// <summary>
        /// Supplement necessary background information
        /// </summary>
        [JsonPropertyName("background_setting")]
        public string BackgroundSetting { get; set; } = string.Empty;



        /// <summary>
        /// Convert entity class to Markdown format for LLM
        /// </summary>
        public string ToMarkdown()
        {
            var sb = new StringBuilder();
    
            //sb.AppendLine("Style Guide");
            sb.AppendLine($"- **Category**: {Category}");
            sb.AppendLine($"- **Overall Tone**: {string.Join(", ", OverallTone)}");
            sb.AppendLine($"- **Style Instructions**: {StyleInstruction}");
            sb.AppendLine($"- **Address Strategy**: {PronounRules}");
            sb.AppendLine($"- **Summary**: {Summary}");
            sb.AppendLine($"- **Background Info**: {BackgroundSetting}");
    
            return sb.ToString();
        }
    }


    #endregion
}
using Microsoft.Agents.AI;
using Microsoft.Extensions.AI;
using Microsoft.Extensions.Logging;
using Subtitles.Translate.Agent.Core.Models;
using System.Text;
using System.Text.Json.Serialization;

namespace Subtitles.Translate.Agent.Core.Agents
{
    /// <summary>
    /// Step 2: Glossary Agent
    /// Based on subtitle text and plot analysis, extract proper nouns and build a bilingual glossary
    /// </summary>
    public class Step2_GlossaryAgent : AgentBase
    {
        public const string AgentName = nameof(Step2_GlossaryAgent);
        private readonly AIAgent _agent;

        public Step2_GlossaryAgent(WorkflowContext context)
            : base(context, AgentName)
        {
            // Create ChatClient and initialize Agent
            var client = CreateChatClient();
            _agent = client.CreateAIAgent().AsBuilder().Build();
        }
    
        public override async Task ExecuteAsync()
        {
            _logger?.LogInformation("===== {AgentName} started execution =====", AgentName);
    
            var prompt = GetPrompt();
            _logger?.LogDebug("Prompt length: {Length} chars", prompt.Length);
    
            _logger?.LogInformation("Calling LLM (Model: {ModelId})...", _agentConfig.ModelId);
            var response = await _agent.RunAsync(prompt);
            _logger?.LogInformation("LLM response completed");
    
            // Record Token usage to context
            RecordTokenUsage(AgentName, response.Usage);
            _logger?.LogDebug("Token Usage - Input: {Input}, Output: {Output}, Total: {Total}",
                response.Usage?.InputTokenCount ?? 0,
                response.Usage?.OutputTokenCount ?? 0,
                response.Usage?.TotalTokenCount ?? 0);
    
            // Save raw response
            _context.Step2_GlossaryRaw = response.Text;
            _logger?.LogDebug("Raw response length: {Length} chars", response.Text?.Length ?? 0);
    
            // Use base class method to extract and parse JSON
            _context.Step2_GlossaryResult = ParseJsonResponse<Step2_GlossaryResult>(response.Text ?? string.Empty);
    
            // Output parsing result summary
            if (_context.Step2_GlossaryResult != null)
            {
                _logger?.LogDebug("Parsing successful:");
                _logger?.LogDebug(_context.Step2_GlossaryResult.ToMarkdown());
            }
            else
            {
                throw new Exception("Step 2: Result Is null");
            }


            _logger?.LogInformation("===== {AgentName} execution completed =====", AgentName);
        }
    
        public string GetPrompt()
        {
            var prompt = $$"""
# Role
You are a terminology management expert with 20 years of experience (Terminology Manager). Your specialty is building precise **Bilingual Controlled Vocabularies**, ensuring high consistency in proper nouns, character names, and industry terms, fitting the reading habits of the target audience.

# Task
Based on the provided **[Original Subtitle Text]** and **[Step 1 Translation Guidance]**, extract all key entities and build a **JSON Format Glossary**.

# Inputs
1. **Translation Strategy (from Step 1)**:
{{_context.Step1_DirectorResult!.ToMarkdown()}}
*(Note: Use `Summary` and `Style Instructions` from Step 1 to determine the style of translated names. For example: if "Fantasy", names should lean towards classical; if "Hard Sci-Fi", names should be accurate and professional.)*

2. **Subtitle Content**:
{{_context.FormattedSubtitle}}

# Goals
You need to identify the following three types of entities and generate corresponding standard translations in the target language:

1.  **Characters**:
    * Extract all names and code names.
    * **Critical Task 1**: Must infer **Gender** based on context and Step 1's `pronoun_rules`.
    * **Critical Task 2**: Identify different forms of address for the same character (e.g., "William" and "Bill") and associate them in the JSON.

2.  **Locations**:
    * Extract cities, landmarks, fictional realms.
    * **Strategy**: Use standard translations for real places (New York -> 纽约); use transliteration or semantic translation for fictional places based on Step 1's tone (Rivendell -> 瑞文戴尔).

3.  **Specific Terms (Proper/Industry Terms)**:
    * Extract organizations, special items, magic spells, tech concepts, specific industry jargon.
    * **Strategy**: Since Step 1 has defined `category` (e.g., Medical Drama), ensure extracted term translations meet professional standards for that domain.

# Analysis Requirements (JSON Fields)

Please generate a JSON object containing the following fields:

1.  **character_map**:
    * `source_name`: Standard name in original text (capitalized).
    * `aliases`: [Array] Other names for this character appearing in the text (nicknames, surnames, code names).
    * `target_name`: Standard {{_context.Request.TargetLanguage}} translation.
    * `gender`: "male" / "female" / "unknown" / "object".
    * `context_note`: Short note (identity, relationship) to help subsequent translation understand why this name was chosen.

2.  **location_map**:
    * `source_term`: Original location name.
    * `target_term`: Standard {{_context.Request.TargetLanguage}} translation.
    * `type`: Location category (Real/Fictional/Micro-location).

3.  **terminology_map**:
    * `source_term`: Original term.
    * `target_term`: Standard {{_context.Request.TargetLanguage}} translation.
    * `domain`: Domain (based on Step 1 category, e.g., "Magic", "Cybernetics", "Legal").
    * `definition`: Short explanation to prevent ambiguity.

# Constraints
1.  **Exclusion**: Strictly forbid extracting common words (e.g., "morning", "officer", "teacher") unless they are part of a proper noun (e.g., "Officer Judy").
2.  **Context-Aware**: If a word is both a name and a common word (e.g., "Summer"), judge whether to extract based on plot.
3.  **JSON Only**: Output must be pure JSON, no text other than Markdown tags.
4.  **Empty Handling**: If a category of entities does not exist, return an empty array `[]`.

# Output Example
{
  "character_map": [
    {
      "source_name": "William Butcher",
      "aliases": ["Billy", "Butcher"],
      "target_name": "威廉·布彻",
      "gender": "male",
      "context_note": "One of the protagonists, violent temper, usually called Billy"
    }
  ],
  "location_map": [
    {
      "source_term": "Vought Tower",
      "target_term": "沃特大厦",
      "type": "Fictional Landmark"
    }
  ],
  "terminology_map": [
    {
      "source_term": "Compound V",
      "target_term": "五号化合物",
      "domain": "Bio-Tech",
      "definition": "Drug in the show that gives people superpowers"
    }
  ]
}
""";

            return prompt;
        }
    }
    
    #region Step2 Result Models
    
    /// <summary>
    /// Step 2 Glossary Analysis Result
    /// </summary>
    public class Step2_GlossaryResult
    {
        /// <summary>
        /// Character Map
        /// </summary>
        [JsonPropertyName("character_map")]
        public List<CharacterEntry> CharacterMap { get; set; } = new();
    
        /// <summary>
        /// Location Map
        /// </summary>
        [JsonPropertyName("location_map")]
        public List<LocationEntry> LocationMap { get; set; } = new();
    
        /// <summary>
        /// Terminology Map
        /// </summary>
        [JsonPropertyName("terminology_map")]
        public List<TerminologyEntry> TerminologyMap { get; set; } = new();
    
        /// <summary>
        /// Convert entity class to Markdown format for LLM
        /// </summary>
        public string ToMarkdown()
        {
            var sb = new StringBuilder();
    
            // 1. Characters
            if (CharacterMap != null && CharacterMap.Any())
            {
                sb.AppendLine("- Character Mapping");
                foreach (var charItem in CharacterMap)
                {
                    // Format: - **Source** (aka Alias): Target (Gender: X, Note: Y)
                    var aliasPart = (charItem.Aliases != null && charItem.Aliases.Any())
                                    ? $" (aka: {string.Join(", ", charItem.Aliases)})"
                                    : "";
                    var notePart = string.IsNullOrWhiteSpace(charItem.ContextNote)
                                   ? ""
                                   : $", Note: {charItem.ContextNote}";
    
                    sb.AppendLine($"    - **{charItem.SourceName}**{aliasPart}: {charItem.TargetName} (Gender: {charItem.Gender}{notePart})");
                }
                sb.AppendLine();
            }
    
            // 2. Locations
            if (LocationMap != null && LocationMap.Any())
            {
                sb.AppendLine("- Place Name Mapping");
                foreach (var loc in LocationMap)
                {
                    // Format: - **Source**: Target (Type: X)
                    sb.AppendLine($"    - **{loc.SourceTerm}**: {loc.TargetTerm} (Type: {loc.Type})");
                }
                sb.AppendLine();
            }
    
            // 3. Terminology
            if (TerminologyMap != null && TerminologyMap.Any())
            {
                sb.AppendLine("- Terminology Table");
                foreach (var term in TerminologyMap)
                {
                    // Format: - **Source**: Target (Domain: X, Def: Y)
                    var defPart = string.IsNullOrWhiteSpace(term.Definition) ? "" : $", Def: {term.Definition}";
                    sb.AppendLine($"    - **{term.SourceTerm}**: {term.TargetTerm} (Domain: {term.Domain}{defPart})");
                }
            }
    
            return sb.ToString();
        }
    }
    
    /// <summary>
    /// Character Entry
    /// </summary>
    public class CharacterEntry
    {
        /// <summary>
        /// Original name (full spelling)
        /// </summary>
        [JsonPropertyName("source_name")]
        public string SourceName { get; set; } = string.Empty;
    
        /// <summary>
        /// Other names for this character (nicknames, surnames, code names)
        /// </summary>
        [JsonPropertyName("aliases")]
        public List<string> Aliases { get; set; } = new();
    
        /// <summary>
        /// Standard translation
        /// </summary>
        [JsonPropertyName("target_name")]
        public string TargetName { get; set; } = string.Empty;
    
        /// <summary>
        /// Gender: male / female / unknown / object (non-human entity)
        /// </summary>
        [JsonPropertyName("gender")]
        public string Gender { get; set; } = "unknown";
    
        /// <summary>
        /// Short note (identity, relationship)
        /// </summary>
        [JsonPropertyName("context_note")]
        public string ContextNote { get; set; } = string.Empty;
    }
    
    /// <summary>
    /// Location Entry
    /// </summary>
    public class LocationEntry
    {
        /// <summary>
        /// Original location name
        /// </summary>
        [JsonPropertyName("source_term")]
        public string SourceTerm { get; set; } = string.Empty;
    
        /// <summary>
        /// Standard translation
        /// </summary>
        [JsonPropertyName("target_term")]
        public string TargetTerm { get; set; } = string.Empty;
    
        /// <summary>
        /// Category (Real/Fictional/Micro-location)
        /// </summary>
        [JsonPropertyName("type")]
        public string Type { get; set; } = string.Empty;
    }
    
    /// <summary>
    /// Terminology Entry
    /// </summary>
    public class TerminologyEntry
    {
        /// <summary>
        /// Original term
        /// </summary>
        [JsonPropertyName("source_term")]
        public string SourceTerm { get; set; } = string.Empty;
    
        /// <summary>
        /// Standard translation
        /// </summary>
        [JsonPropertyName("target_term")]
        public string TargetTerm { get; set; } = string.Empty;
    
        /// <summary>
        /// Domain
        /// </summary>
        [JsonPropertyName("domain")]
        public string Domain { get; set; } = string.Empty;
    
        /// <summary>
        /// Short definition
        /// </summary>
        [JsonPropertyName("definition")]
        public string Definition { get; set; } = string.Empty;
    }
    
    #endregion
}

using Microsoft.Agents.AI;
using Microsoft.Extensions.AI;
using Microsoft.Extensions.Logging;
using Subtitles.Translate.Agent.Core.Models;
using System.Collections.Generic;
using System.Text;
using System.Text.Json;
using System.Text.Json.Serialization;

namespace Subtitles.Translate.Agent.Core.Agents
{
    /// <summary>
    /// Step 3: Subtitle Translation Agent
    /// Translates subtitles using a sliding window approach, supporting context reference
    /// </summary>
    public class Step3_TranslatorAgent : AgentBase
    {
        public const string AgentName = nameof(Step3_TranslatorAgent);
        private readonly AIAgent _agent;
        private int _currentBatchIndex;

        public Step3_TranslatorAgent(WorkflowContext context)
            : base(context, AgentName)
        {
            // Create ChatClient and initialize Agent
            var client = CreateChatClient();
            _agent = client.CreateAIAgent().AsBuilder().Build();
    
        }
    
        /// <summary>
        /// Execute sliding window translation
        /// </summary>
        public override async Task ExecuteAsync()
        {
            _logger?.LogInformation("===== {AgentName} started execution =====", AgentName);
    
            var totalLines = _context.Subtitle.Paragraphs.Count;
            var batchSize = _context.Request.BatchSize;
    
            // Initialize translation results and progress
            _context.TranslatedItems = new List<TranslationItem>();
            _context.TranslationProgress ??= new TranslationProgress
            {
                TotalLines = totalLines,
                TotalBatches = (int)Math.Ceiling((double)totalLines / batchSize)
            };
    
            _logger?.LogDebug("Total subtitles: {Total}, Batch size: {BatchSize}, Total batches: {TotalBatches}",
                totalLines, batchSize, _context.TranslationProgress.TotalBatches);
    
            // Sliding window translation loop
            int startIndex = _context.TranslatedItems.Count;
            while (startIndex < totalLines)
            {
                _currentBatchIndex = _context.TranslationProgress.CurrentBatchIndex;
                int batchEnd = Math.Min(startIndex + batchSize, totalLines);
    
                // Batch translation with retry
                List<TranslationItem>? translations = null;
                int maxRetries = _context.MaxRetries;
                int retryCount = 0;
                Exception? lastException = null;
    
                while (retryCount <= maxRetries)
                {
                    try
                    {
                        translations = await ProcessBatchAsync(startIndex, batchEnd);
                        retryCount = 0;
                        break; // Break retry loop on success
                    }
                    catch (Exception ex)
                    {
                        lastException = ex;
                        retryCount++;
    
                        if (retryCount <= maxRetries)
                        {
                            _logger?.LogWarning(ex, "Batch {BatchIndex} translation failed, retrying {RetryCount}/{MaxRetries}...",
                                _currentBatchIndex, retryCount, maxRetries);
    
                            // Exponential backoff delay to avoid immediate retry
                            int delayMs = Math.Min(1000 * (int)Math.Pow(2, retryCount - 1), 30000);
                            await Task.Delay(delayMs);
                        }
                        else
                        {
                            _logger?.LogError(ex, "Batch {BatchIndex} translation failed, reached max retries {MaxRetries}",
                                _currentBatchIndex, maxRetries);
                            throw new InvalidOperationException(
                                $"Batch {_currentBatchIndex} (Subtitle {startIndex}-{batchEnd - 1}) translation failed, retried {maxRetries} times. Error: {ex.Message}", ex);
                        }
                    }
                }
    
                if (translations != null)
                {
                    LogBatchDetails(translations);
                    _context.TranslatedItems.AddRange(translations);
                }
    
                // Update progress
                _context.TranslationProgress.TranslatedLines = _context.TranslatedItems.Count;
                _context.TranslationProgress.CurrentBatchIndex++;
                startIndex = batchEnd;
            }
    
            _logger?.LogInformation("===== {AgentName} execution completed, translated {Count} subtitles =====",
                AgentName, _context.TranslatedItems.Count);
        }
    
        /// <summary>
        /// Process a single batch translation workflow
        /// </summary>
        private async Task<List<TranslationItem>?> ProcessBatchAsync(int startIndex, int batchEnd)
        {
            int batchSize = batchEnd - startIndex;
            _logger?.LogInformation("Processing batch {BatchIndex}: Subtitles {Start}-{End} (Total {Count} items)",
                _currentBatchIndex, startIndex, batchEnd - 1, batchSize);
    
            // Build batch data and generate prompt
            var batchData = BuildBatchData(startIndex, batchEnd);
            var prompt = GetPrompt(batchData);
            _logger?.LogDebug("Prompt /n:{prompt}", prompt);
            _logger?.LogDebug("Prompt length: {Length} chars", prompt.Length);
    
            // Call AI translation
            _logger?.LogInformation("Calling LLM (Model: {ModelId})...", _agentConfig.ModelId);
            var response = await _agent.RunAsync(prompt);
            RecordTokenUsage(AgentName, response.Usage, _currentBatchIndex);
            _logger?.LogDebug("Token usage - Input: {Input}, Output: {Output}",
                response.Usage?.InputTokenCount ?? 0, response.Usage?.OutputTokenCount ?? 0);
    
            // Parse and verify results
            var rawResults = ParseJsonResponse<List<Step3_TranslateResult>>(response.Text);



            // Verify translation result quantity
    
            if (rawResults == null || rawResults.Count == 0 || rawResults.Count != batchSize)
            {
                throw new InvalidOperationException(
                    $"Translation result count mismatch. Expected: {batchSize}, Actual: {rawResults?.Count ?? 0}. Batch range: {startIndex}-{batchEnd - 1}");
            }
    
            // Convert to TranslationItem
            var translations = rawResults.Select(r => new TranslationItem
            {
                Id = r.Id,
                Original = r.Original,
                InitialTranslation = r.InitialTranslation
            }).ToList();
    
            return translations;
        }
    
        /// <summary>
        /// Build current batch data
        /// </summary>
        private BatchData BuildBatchData(int startIndex, int endIndex)
        {
            var paragraphs = _context.Subtitle.Paragraphs;
            var request = _context.Request;
    
            // Preceding context (translated)
            var precedingStart = Math.Max(0, startIndex - request.PrecedingContextLines);
            var precedingContext = Enumerable.Range(precedingStart, startIndex - precedingStart)
                .Select(i => (i, paragraphs[i].Text, _context.TranslatedItems?.ElementAtOrDefault(i)?.InitialTranslation))
                .ToList();
    
            // Current batch
            var currentBatch = Enumerable.Range(startIndex, endIndex - startIndex)
                .Select(i => (i, paragraphs[i].Text))
                .ToList();
    
            // Following context (untranslated preview)
            var followingEnd = Math.Min(paragraphs.Count, endIndex + request.FollowingContextLines);
            var followingContext = Enumerable.Range(endIndex, followingEnd - endIndex)
                .Select(i => (i, paragraphs[i].Text))
                .ToList();
    
            return new BatchData
            {
                PrecedingContext = precedingContext,
                CurrentBatch = currentBatch,
                FollowingContext = followingContext
            };
        }
    
        /// <summary>
        /// Generate translation prompt
        /// </summary>
        private string GetPrompt(BatchData batchData)
        {
            var request = _context.Request;
    
            // Build context strings
            var precedingContextStr = FormatContextLines(batchData.PrecedingContext);
            var currentBatchStr = FormatBatchLines(batchData.CurrentBatch);
            var followingContextStr = FormatBatchLines(batchData.FollowingContext);
    
            var prompt = $$"""
# Role
You are a senior film and television subtitle translation expert proficient in multiple languages. You possess strong context awareness and can read project documents to translate scattered subtitle fragments into fluent, natural translations that fit the target audience's habits.

# Task
Based on the provided **[Style Guide]**, **[Glossary]**, and **[Dialogue Context]**, translate the current **[Subtitle Batch]** into the target language.

# Source Language
**Auto-Detect (Please detect source language based on input text)**

# Target Language
**{{request.TargetLanguage}}**

# Inputs (Reference Documents)

## 1. Style Guide
*Document Content*:
{{_context.Step1_DirectorResult!.ToMarkdown()}}

*Instructions*:
- **Tone**: Read "Overall Tone" carefully, ensure the translation fits the emotional color (e.g., serious, humorous, confrontational).
- **Style**: Strictly follow "Style Instructions" (e.g., news broadcast style, colloquialism level).
- **Address**: Refer to "Address Strategy" to clarify relationships and address strategies between characters/speakers.


## 2. Glossary
*Document Content*:
{{_context.Step2_GlossaryResult!.ToMarkdown()}}

*CRITICAL INSTRUCTION*:
- **Characters**: Look up names in `- Character Mapping`. Must use the translated name specified in the document. Use pronouns (he/she) accurately based on Gender in remarks.
- **Terms**: Look up proper nouns in `- Place Name Mapping` and `- Terminology Table`. If the original text appears in the list, **you must use** the corresponding translated name in the document, and are strictly forbidden from improvising.

## 3. Context Stream
- **Preceding Context (Translated)**:
{{precedingContextStr}}
*(Used to maintain tone continuity, do not re-translate this part)*

- **Following Context (Preview)**:
{{followingContextStr}}
*(For reference only to eliminate ambiguity, **absolutely do not** translate this part)*

## 4. Current Subtitle Batch
{{currentBatchStr}}

# Translation Process Rules

1.  **Semantic Fusion**:
    - Subtitles are often cut by the timeline (cross-line sentence breaking).
    - **Must** first piece together multiple lines of original text into a complete sentence in your mind, understand the full meaning, translate, and then split back to the corresponding lines according to the original ID.
    - *Prohibit* word-for-word translation (e.g., Line 1 "I decided to" -> "我决定去", Line 2 "give up" -> "放弃" ——> Should be optimized to Line 1 "我决定", Line 2 "放弃了").

2.  **Contextual Adaptation**:
    - Combine background information from Step 1 to identify subtext.
    - If the original text contains pronouns (It/He/They), must combine context to clarify the object and avoid ambiguity.

3.  **Format Integrity**:
    - Translation length should fit the original duration as much as possible to avoid reading difficulties caused by excessive length.
    - Punctuation marks must comply with target language norms.

# Output Requirements

1.  **Structure**: Output pure JSON array, strictly forbid including Markdown (` ```json `) or other explanatory text.
2.  **Quantity Check**: The number of array elements returned must be exactly the same as `Current Subtitle Batch` (**Exactly {{batchData.CurrentBatch.Count}} items**, ID range: {{batchData.CurrentBatch.First().Index}} to {{batchData.CurrentBatch.Last().Index}}).
3.  **Format**:
    [
      {
    "id": "Keep original ID",
    "original": "Original content (kept for verification)",
    "initial_translation": "Final translation"
      }
    ]
    """;

            return prompt;
        }
        
        /// <summary>
        /// Format preceding context (includes original and translation)
        /// </summary>
        private static string FormatContextLines(List<(int Index, string Original, string? Translation)> lines)
        {
            var sb = new StringBuilder();
            foreach (var (index, original, translation) in lines)
            {
                sb.AppendLine($"[{index}] {original}");
                sb.AppendLine($"    → {translation ?? "(Untranslated)"}");
            }
            return sb.ToString();
        }
        
        /// <summary>
        /// Format batch/following context (original only)
        /// </summary>
        private static string FormatBatchLines(List<(int Index, string Text)> lines)
        {
            var sb = new StringBuilder();
            foreach (var (index, text) in lines)
                sb.AppendLine($"[{index}] {text}");
            return sb.ToString();
        }
        
        /// <summary>
        /// Log batch translation details
        /// </summary>
        private void LogBatchDetails(List<TranslationItem> translations)
        {
            if (_logger == null || translations == null || translations.Count == 0) return;
        
            var sb = new StringBuilder();
            sb.AppendLine($"\n===== Batch {_currentBatchIndex} Translation Details =====");
        
            foreach (var item in translations)
            {
                sb.AppendLine($"ID: {item.Id}");
                sb.AppendLine($"Original: {item.Original}");
        
                // Review info
                if (!string.IsNullOrEmpty(item.ReviewStatus)
                    && item.ReviewStatus != "PASS")
                {
                    sb.AppendLine($"Initial: {item.InitialTranslation ?? item.Translation}"); // If no InitialTranslation (should not happen theoretically), fallback to Translation
                    sb.AppendLine($"Review [{item.ReviewStatus}]: {item.ReviewCritique ?? "No comment"}");
                    sb.AppendLine($"Post-Review: {item.ReviewFinalTranslation}");
                }
        
                sb.AppendLine($"Final Translation: {item.Translation}");
                sb.AppendLine(new string('-', 30));
            }
        
            _logger.LogDebug(sb.ToString());
        }


    }
    
    /// <summary>
    /// Batch data structure
    /// </summary>
    public class BatchData
    {
        /// <summary>
        /// Preceding context (translated)
        /// </summary>
        public List<(int Index, string Original, string? Translation)> PrecedingContext { get; set; } = new();
    
        /// <summary>
        /// Current batch to translate
        /// </summary>
        public List<(int Index, string Text)> CurrentBatch { get; set; } = new();
    
        /// <summary>
        /// Following context (untranslated, preview only)
        /// </summary>
        public List<(int Index, string Text)> FollowingContext { get; set; } = new();
    }
    
    /// <summary>
    /// Step 3 translation result entity
    /// </summary>
    public class Step3_TranslateResult
    {
        [JsonPropertyName("id")]
        public string Id { get; set; } = string.Empty;
    
        [JsonPropertyName("original")]
        public string Original { get; set; } = string.Empty;
    
        [JsonPropertyName("initial_translation")]
        public string InitialTranslation { get; set; } = string.Empty;
    }
}

---
这个开源项目 `Subtitles.Translate.Agent` 的核心架构是一个典型的**多代理协同（Multi-Agent Collaboration）工作流**。它通过将翻译任务拆分为“策略制定”、“术语提取”和“流式翻译”三个阶段，解决了大模型在处理长文本时容易丢失上下文、术语不一致以及翻译腔过重的问题。

针对你关注的**分割、合并、翻译、定位还原**流程，以下是该项目的实现逻辑分析：

------

## 1. 核心流程架构

### 第一阶段：Director Agent (全局策略)

在进行任何翻译之前，`Step1_DirectorAgent` 首先阅读**全部字幕**。

- **分析**：识别视频类型（如：科技教程、Cyberpunk电影、Vlog）。
- **决策**：确立“语体（Register）”（如：是该用“您”还是“你”）、“风格指南”和“背景设定”。
- **作用**：这相当于给大模型打了一个“预防针”，防止它在第一句用正式语，第二句突然变口语。

### 第二阶段：Glossary Agent (术语提取与对齐)

`Step2_GlossaryAgent` 负责从全文中提取实体。

- **识别**：找出人名（判定性别以准确使用 he/she）、地名、专业术语。
- **对齐**：在翻译开始前就确定好这些词的统一译名。
- **作用**：解决了你担心的“翻译一致性”问题，比如同一个角色名不会在视频前半段叫“约翰”，后半段叫“强尼”。

### 第三阶段：Translator Agent (滑动窗口翻译与还原)

这是最关键的执行层，采用了**带上下文的滑动窗口（Sliding Window）**技术。

#### A. 分割与合并逻辑 (Context Stream)

该项目并不只是逐行翻译，而是构建了一个 `BatchData` 结构：

- **Preceding Context (前文)**：带上已经翻译好的几行，确保语气连贯。
- **Current Batch (当前块)**：本次要翻译的原始行。
- **Following Context (后文预览)**：提供未翻译的后几行作为参考，防止语义断层。

#### B. 语义融合 (Semantic Fusion)

在 Prompt 中，它明确指示 LLM：

> "Subtitles are often cut by the timeline... Must first piece together multiple lines... and then split back to the corresponding lines according to the original ID."

- **实现**：要求 LLM 将被时间轴切断的句子在脑海中“缝合”，翻译成完整的长句，再根据原始 ID 拆回对应的行。这样解决了“逐字翻译”导致的句子支离破碎问题。

#### C. 定位还原

- **ID 绑定**：每个字幕行都带有一个 `Index` 或 `Id`。
- **强制约束**：通过 Prompt 强力约束 LLM 输出的 JSON 数组数量必须与输入一致，且 ID 必须匹配。
- **格式还原**：最终返回 `initial_translation`。因为原始 ID 没变，系统可以直接根据 ID 将译文塞回原始的字幕结构（如 JSON 或 SRT）中，实现精准的时间轴对齐。

------

## 2. 针对你 YouTube 方案的深度建议

结合你的服务器中转想法和这个项目的思路，有几个关键点可以优化：

### 1. 异步处理与“三段式”缓存

由于 YouTube 的接口超时非常严（通常几秒内），而大模型翻译整段视频可能需要 30s 到 1min。

- **状态 1 (Cache Miss)**：用户请求中文，你的服务发现没有，立即返回原始英文字幕，同时在后台触发 **Step 1 + Step 2 + Step 3** 的全量翻译任务。
- **状态 2 (Processing)**：任务正在跑，后续请求依然返回原文。
- **状态 3 (Completed)**：翻译完成，持久化到数据库。下次请求直接返回双语。

### 2. 关于“合并与拆分”的难点

YouTube 的 `timedtext` 接口返回的是带有精确到单词时间戳的 JSON。

- **推荐做法**：不要试图在 LLM 内部处理微秒级时间戳。你应该像这个项目一样，提取出 `Text` 和 `ID` 交给 LLM。
- **拼接技巧**：利用 LLM 输出 `\n` 实现双语。
  - 原文：`Hello world`
  - 译文：`你好，世界\nHello world`
  - 这样 YouTube 的渲染引擎会自动把第一行当成主要字幕显示。

